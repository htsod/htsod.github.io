[{"content":"Fourier Methods could be derived entirely from Group theory! As the title suggests, the entire concept of the Fourier transform can be derived if we understand some basic group theory. We start by introducing the group \\(Z_{N}\\) and its irreducible represenations. Using the orthogonality theorem, we will then derive the discrete Fourier transform (DFT) and the Fourier transform (FT).\nBefore diving into the mathematics, it\u0026rsquo;s helpful to get an intuitive picture of how these two fields overlap. Fourier analysis studies the periodicities of functions. Any continuous and differentiable function can be broken down into a linear combination of its frequency components, which is the foundation of Fourier series. The Fourier transform allows us to switch between real space and frequency space representations.\nApproaching this from group theory, we recognize that an arbitrary function is a reducible representation of the group \\(Z_{N}\\). Consider a function \\(f(x)\\) that satisfies the periodic condition\n$$ f(x+na) = f(x) $$\nfor \\(n = 0, \\pm1, \\pm2, \u0026hellip;\\). For example, a sinusoidal function \\(f(x) = Asin(\\frac{2\\pi x}{a})\\) satisfies the above condition.\nFourier methods are ubiquitous in daily life. Light and sound waves, for example, can be broken down into Fourier components. These waves represent translational symmetries, propagating as plane waves with frequencies proportional to the eigenvalues of an operator. Schur’s lemma reveals that if a Hermitian operator commutes with the representation of a symmetry group, it can be diagonalized as \\(H = \\lambda I\\) where \\(\\lambda \\) represents the eigenvalues.\nIn the next section, we’ll briefly touch on results from representation theory and use them to derive some key theorems related to the Fourier method.\nRepresentation Theory: The Core Tool One of the most significant results in group theory is Schur\u0026rsquo;s lemma. It states that if an operator \\(H\\) commutes with a group representation \\(D(g)\\), then \\(H\\) must be diagonal, with \\ \\(H = \\lambda I\\). Using this lemma, we can derive some powerful theorems in group representation theory. (For detail derivation, see ( Citation: Zee,\u0026#32;2016 Zee,\u0026#32; A.\u0026#32; (2016). \u0026#32; Group theory in a nutshell for physicists. \u0026#32; Princeton University Press.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=FWkujgEACAAJ ) )\n$$ \\sum_{g}{D^{(r)\\dagger} (g)_ {j}^{i}D^{(s)}(g)_ {k}^{l}} = \\frac{N(G)}{d}\\delta_{l}^{i}\\delta_{j}^{k} $$\nThis relation holds when summing over group element \\(g\\) and representations \\((r)\\) and \\((s)\\) are orthogonal to each other. Some important corollaries include:\nDimensions of the irreducible representations: $$ \\sum_{r}{d_{r}^{2}} = N(G) $$\nOrthogonality of irreducible representations: $$ \\sum_{c}{n_{c}(\\chi^{(r)}(c))^{\\ast} \\chi^{(s)}(c)} = N(G) \\delta ^{rs} $$\nOrthogonality of classes: $$ \\sum_{r}{\\chi^{(r)}(c)^{\\ast} \\chi^{(r)}(c^{\\prime})} = \\frac{N(G)}{n_{c}}\\delta^{cc^{\\prime}}$$\nNumber of irreducible representation equal to the number of class in the group:\n$$ N(C) = N(R) $$\nA test on reducibility: $$ \\sum_{c}{n_{c} \\chi^{\\ast(r)}\\chi(c)} = N(G)n_{r} $$\nSymmetry and \\(Z_{N}\\) Our first exposure to the Fourier transform is often linked to periodicity, a pattern repeating in time. However, group theory doesn\u0026rsquo;t care if the pattern is in time or any other variable, as long as the symmetry holds. Consider partitioning a rotation of \\(2\\pi\\) into \\( N \\) parts on the complex plane, represented as \\(e^{i\\frac{2\\pi}{N}j}\\) for \\(j = 0, 1, \u0026hellip;, N-1\\). This is the \\(Z_{N}\\) group where \\(g^{N} = I\\). Since \\(Z_{N}\\) is an abelian, each element forms its own class, and each irreducible representation has a dimension of 1.\nBy guessing an irreducible representation that satisfies the multiplication structure: $$ D(e^{i\\frac{2\\pi}{N}j})D(e^{i\\frac{2\\pi}{N}j^{\\prime}}) = D(e^{i\\frac{2\\pi}{N}(j+j^{\\prime})}) $$\nwe propose:\n$$ D(e^{i\\frac{2\\pi}{N}j}) = e^{i\\frac{2\\pi}{N}jk} \\quad k = 0, 1, \u0026hellip;, N-1$$\nNow, using orthogonality:\n$$ \\frac{1}{N}\\sum_{j=0}^{N}{e^{-i\\frac{2\\pi}{N}jk} e^{i\\frac{2\\pi}{N}jk^{\\prime}}} = \\delta^{kk^{\\prime}} $$\nThis gives us the discrete Fourier transform (DFT) and its inverse.\nThis is the same old discrete fourier transform and inverse discrete fourier transform but entirely from group theory along.\nOkay, but how about the idea that for a given function that compose of different vibration mode. Recall that we could break down that function into weighted component of fourier parts. What do group theoretic approach has to do with this?\nWe recognize this given function as an reducible representation that contains various irreducible representation \\(n_{r}\\) times.\nSo, given the reducible representation \\(\\chi(j)\\) applying the test of reducibility gives the weight of the fourier component \\( n_{k} \\)\n$$ \\frac{1}{N} \\sum_{k=0}^{N-1}{e^{-i\\frac{2\\pi}{N}jk} \\chi(j)}= n_{k} $$\nThen, the reducible representation can be written as the sum of each of irreducible representation with weight \\( n_{k} \\)\n$$ \\chi(j) = \\sum_{k=0}^{N-1}{n_{k}e^{i\\frac{2\\pi}{N}jk}} $$\nAlso known as the Fourier series.\nContinum limit: from \\(Z_{N}\\) to \\(U(1)\\) and from DFT to FT To extend the DFT to the continuous Fourier transform (FT), we take the limit \\(N \\rightarrow \\infty\\). The discrete group \\(Z_{N}\\) becomes \\(U(1)\\), and the summation becomes integration:\n$$\\sum_{k=0}^{N-1} \\rightarrow \\int_{0}^{\\infty}d\\mu(g)$$\nwhere \\(\\mu(g)\\) is the group measure.\nTo evaluate the orthogonality relation in the continuous case, one has to find the trace and the group measure as demonstrated as follow.\nfinding the trace \\(U(1)\\) group has the property that \\(U^{\\dagger}U = I\\). For \\(U(1)\\), it furnishes one dimension representation only and hence the trace of the representation is just the representation itself. We propose that \\(D(\\theta) = \\chi(\\theta, k) = e^{i\\theta k}\\). It clearly satisfies the unitary condition and preserve the algebraic structure of the group multiplication. The only difference is that now \\(\\theta\\) runs as continuous variable from \\(0 \u0026lt; \\theta \u0026lt;2\\pi\\).\nfinding the group measure The purpose of finding a group measure is to make the integral cover the group manifold. Hence, we could intepret the group measure \\(d\\mu(g)\\) runs over the group manifold. In this trivial case of \\(U(1)\\), the group manifold is merely a cycle and hence to cover the manifold we propose the following integral \\(\\int_{0}^{2\\pi}{d\\theta}\\).\nApplying orthogonality, we obtain:\n$$ \\int_{U(1)}{\\chi^{\\ast}(k,g)\\chi(k^{\\prime},g)d\\mu(g)} = \\int_{0}^{2\\pi}{e^{-i\\theta k^{\\prime}}e^{i\\theta k}d\\theta} = 2\\pi \\delta_{kk^{\\prime}}$$\nThus, we arrive at the Fourier transform.\nFinal Remark To summarize, from group theory, we recover the following results:\nFrom Discrete Group\nDFT:\\( \\frac{1}{N}\\sum_{j=0}^{N}{e^{-i\\frac{2\\pi}{N}jk} e^{i\\frac{2\\pi}{N}jk^{\\prime}}} = \\delta^{kk^{\\prime}} \\)\nInverse DFT:\\( \\sum_{k=0}^{N}{e^{-i\\frac{2\\pi}{N}jk} e^{i\\frac{2\\pi}{N}j^{\\prime}}} = \\delta^{jj^{\\prime}} \\)\nFourier Series: \\( \\chi(j) = \\sum_{k=0}^{N-1}{n_{k}e^{i\\frac{2\\pi}{N}jk}} \\)\nFrom Continuous Group\nFourier Transform: \\( \\int_{U(1)}{\\chi^{\\ast}(k,g)\\chi(k^{\\prime},g)d\\mu(g)} = \\int_{0}^{2\\pi}{e^{-i\\theta k^{\\prime}}e^{i\\theta k}d\\theta} = 2\\pi \\delta_{kk^{\\prime}} \\) One advantage of viewing the Fourier method through the lens of group theory is that it reveals Fourier methods as simply a consequence of translational symmetry. This perspective allows for potential generalizations to other orthogonality theorems, such as those based on symmetries like \\(SU(3)\\) in particle physics, which underpins the Standard Model.\nBibliography Zee (2016) Zee,\u0026#32; A.\u0026#32; (2016). \u0026#32; Group theory in a nutshell for physicists. \u0026#32; Princeton University Press.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=FWkujgEACAAJ ","permalink":"https://htsod.github.io/posts/fourier/","summary":"\u003ch2 id=\"fourier-methods-could-be-derived-entirely-from-group-theory\"\u003eFourier Methods could be derived entirely from Group theory!\u003c/h2\u003e\n\u003cp\u003eAs the title suggests, the entire concept of the Fourier transform can be derived if we understand some basic group theory. We start by introducing the group \\(Z_{N}\\) and its irreducible represenations. Using the orthogonality theorem, we will then derive the discrete Fourier transform (DFT) and the Fourier transform (FT).\u003c/p\u003e\n\u003cp\u003eBefore diving into the mathematics, it\u0026rsquo;s helpful to get an intuitive picture of how these two fields overlap. Fourier analysis studies the periodicities of functions. Any continuous and differentiable function can be broken down into a linear combination of its frequency components, which is the foundation of Fourier series. The Fourier transform allows us to switch between real space and frequency space representations.\u003c/p\u003e","title":"Group Theoretic Approach on Fourier Method"},{"content":" Anyone is feeling weird? The contradiction between classical physics and microscopic phenomena is one of the most fascinating episodes in the history of science, reshaping our fundamental understanding of waves and particles. To grasp the weirdness of wave-particle duality, let’s start with a simple analogy.\nImagine shooting bullets at a wall with two equally spaced gaps. As expected, the bullets passing through each gap will behave independently, forming two distinct patterns on a measurement panel behind the wall. Each pattern would look like a Gaussian distribution centered around the corresponding slit. The resulting measurement would be a straightforward combination of these two distributions:\n$$ \\rho_{12}(x) = \\rho_{1}(x) + \\rho_{2}(x) $$\nThis is because the events are independent, and the densities of bullet impacts simply add up.\nNow, let’s replace the bullets with waves—perhaps water waves or sound waves—propagating through the same two slits. Experimentally, something entirely different occurs. Instead of the waves passing independently through the slits, they interfere with each other, producing a distinctive interference pattern on the panel.\nIf we describe the waves mathematically, let \\( h_{1}(x)e^{i2\\pi \\nu t} \\) and \\( h_{2}(x)e^{i2\\pi \\nu t} \\) represent the waves passing through the first and second slits, respectively. When both slits are open, the total wave is: $$ (h_{1}(x) + h_{2}(x))e^{i2\\pi \\nu t} $$\nThe intensity of this combined wave is given by the square of the total wave function:\n$$ I_{12} = |h_{1}(x) + h_{2}(x)|^{2} = |h_{1}(x)|^{2} + |h_{2}(x)|^{2} + h_{1}(x)h_{2}^{\\ast} + h_{1}(x)^{\\ast}h_{2} $$\nThis reveals something new: the presence of interference terms. Unlike the case with bullets, where the results simply add, waves interact, creating regions of constructive and destructive interference:\n$$ I_{12}(x) = I_{1}(x) + I_{2}(x) + I_{interference}(x) \\neq I_{1}(x) + I_{2}(x) $$\nThe Wave-Particle Mystery This wave-particle duality extends beyond classical waves. Experiments with electrons—and more recently, with larger molecules like \\( C_{60} \\) (the largest known entity to show this duality)—reveal that quantum particles exhibit both wave-like and particle-like behaviors. As the famous physicist Richard Feynman put it:\n\u0026hellip; a phenomennon which is impossible, absolutely impossible, to explain in any classical way, and which has in the heart of quantum mechanics, \u0026hellip; We can not make the mystery go away by \u0026rsquo;explaining\u0026rsquo; how it works. We will just tell you how it works.\nThis duality isn’t the only strange aspect of quantum mechanics. Quantum effects are also evident in blackbody radiation and spectroscopy. In the case of blackbody radiation, it became necessary to assume that energy levels are discrete to match experimental data. In spectroscopy, quantum theory governs the probability of transitions between these discrete energy levels.\nTwo Paths to Quantum Mechanics: Schrödinger and Heisenberg Faced with these puzzling phenomena, physicists developed two different mathematical frameworks to describe quantum mechanics. The first was the matrix mechanics approach, formulated by Heisenberg, Born, and Jordan. The second was Schrödinger’s wave mechanics, which, despite starting from a different perspective, led to the same numerical results.\nFor the sake of clarity in our ongoing discussion of wave-particle duality, we will first explore Schrödinger’s wave equation, which builds directly on the wave-like nature of quantum systems. Heisenberg’s matrix mechanics, while equally valid, feels more like the \u0026ldquo;black magic\u0026rdquo; of theoretical physics—it’s powerful but requires more effort to follow. We’ll dive into that after setting the stage with Schrödinger\u0026rsquo;s more intuitive approach.\n( Citation: Zeng,\u0026#32;2008 Zeng,\u0026#32; J.\u0026#32; (2008). \u0026#32; 量子力学教程. \u0026#32; 科学出版社.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=foQcPwAACAAJ ) The \u0026ldquo;Wave Equation\u0026rdquo; Approach to Quantum Mechanics: Abandoning Preconceived Notions Louis de Broglie proposed that every particle possesses a wavelength, which is related to its wave vector \\( |\\vec{k}| = 2\\pi \\lambda \\).\nFor a free particle, the energy is given by \\( E = p^{2}/2m \\). We can relate energy to angular frequency \\( \\omega \\) using \\( w=E/\\hbar \\) connect the wave vector \\( |\\vec{k}| \\) to momentum through \\( \\vec{k} = \\vec{p}/\\hbar \\). Schrödinger found inspiration in these ideas as he sought to explain wave-particle duality.\nHis journey toward the formulation of the Schrödinger equation began with a question from P. Debye:\nYou speak about waves, but where is the wave equation?\nHistorically, Schrödinger derived the wave function from the classical action principle. However, we will focus directly on the wave function ansatz to derive the Schrödinger equation.\nDeriving the Schrödinger Equation Consider a free particle with energy \\( E = \\frac{p^{2}}{2m} \\). According to de Broglie\u0026rsquo;s principle, this particle has an angular frequency \\( w = \\frac{E}{\\hbar} \\) and a wave vector \\( \\vec{k} = \\frac{\\vec{p}}{\\hbar} \\). We can suggest an ansatz for the wave function as a plane wave:\n$$ \\psi(r,t) \\sim e^{i(\\vec{k}\\cdot\\vec{r}-wt)} = e^{i(\\vec{p}\\cdot\\vec{r} -Et)/\\hbar} $$\nFrom this, we can derive:\n$$ i\\hbar \\frac{\\partial}{\\partial t}\\psi = E \\psi $$ $$ -i\\hbar \\nabla \\psi = \\vec{p}\\psi, -\\hbar^{2}\\nabla ^{2} \\psi = p^{2}\\psi $$\nFor a free particle, since \\(E = p^{2}/2m\\), we can equate these to obtain:\n$$ \\left( i\\hbar \\frac{\\partial}{\\partial t} + \\frac{\\hbar^{2}}{2m}\\nabla^{2} \\right)\\psi = \\left( E - \\frac{p^{2}}{2m} \\right)\\psi = 0$$\nThis leads to the Schrödinger equation for a free particle:\n$$ -i\\hbar \\frac{\\partial}{\\partial t} \\psi = \\frac{\\hbar^{2}}{2m}\\nabla^{2} \\psi $$\nSuperposition of Solutions The equation is linear, allowing for the superposition of plane wave solutions:\n$$ \\psi(\\vec{r}, t) = \\frac{1}{(2\\pi \\hbar)^{3/2}} \\int{\\varphi(\\vec{p}) e^{i(\\vec{p}\\cdot\\vec{r} - Et)/\\hbar} d^{3}p} $$\nSubstituting this expression confirms that it satisfies the Schrödinger equation:\n$$ i\\hbar \\frac{\\partial}{\\partial t}\\psi = \\frac{1}{(2\\pi \\hbar)^{3/2}}\\int{\\varphi(\\vec{p}) E e^{i(\\vec{p}\\cdot\\vec{r} - Et)/\\hbar} d^{3}p } $$\n$$ -\\frac{\\hbar^{2}}{2m}\\nabla^{2} \\psi = \\frac{1}{(2\\pi \\hbar)^{3/2}}\\int{\\varphi(\\vec{p}) p^{2} e^{i(\\vec{p}\\cdot\\vec{r} - Et)/\\hbar} d^{3}p } $$\nThus, we find:\n$$ \\left( i\\hbar \\frac{\\partial}{\\partial t} + \\frac{\\hbar^{2}}{2m}\\nabla^{2} \\right)\\psi = \\int{\\varphi(\\vec{p}) \\left( E - \\frac{p^{2}}{2m} \\right)e^{i(\\vec{p}\\cdot\\vec{r} - Et)/\\hbar} d^{3}p } = 0$$\nAny linear combination of wave packets will satisfy the Schrödinger equation for free particles.\nPromoting Observables to Operators In this derivation, we promote observables namely energy and momentum to operators acting on the wave function:\n$$ E \\rightarrow i\\hbar \\frac{\\partial}{\\partial t}, \\vec{p} \\rightarrow -i\\hbar \\nabla $$\nThe Case of a Particle in a Potential Field Now, let’s consider a particle in a potential field \\( V(\\vec{r}) \\). Based on the nonrelativistic relation of total energy:\n$$ E= \\frac{1}{2m}p^{2} + V(\\vec{r}) $$\nPromoting these quantities to operators yields Schrödinger\u0026rsquo;s equation:\n$$ i\\hbar \\frac{\\partial}{\\partial t}\\psi(\\vec{r}, t) = \\left[ -\\frac{\\hbar^{2}}{2m}\\nabla^{2} + V(\\vec{r})\\right] \\psi(\\vec{r}, t) $$\nImplications of the Schrödinger Equation wave-particle duality: The Schrödinger equation offers a fresh interpretation of matter and waves. In this framework, we retain properties such as mass and charge while moving away from classical trajectories—something we can never truly observe at the microscopic level. Instead, we adopt a probabilistic view of reality. Measurements on a dynamical system with observable \\(O(x)\\) are now defined probabilistically: $$ \\int_{-\\infty}^{\\infty}{\\psi^{\\ast}(x) O(x) \\psi(x)dx} $$\nHere, the statistical interpretation of the wave function leads to the normalization condition:\n$$ \\int_{-\\infty}^{\\infty}{\\psi^{\\ast}(x)\\psi(x)dx } = 1 $$\ndiscrete energy level The Schrödinger equation naturally leads to discrete energy levels due to \u0026ldquo;boundary conditions\u0026rdquo; imposed on \\( \\psi \\) when confined in an infinite potential well. The allowed energy states, or \u0026ldquo;characteristic values,\u0026rdquo; arise from the requirement that the wave function remains bounded. For example, in polar coordinates, the ordinary differential equation has singularities at \\(r=0\\) and \\(r = \\infty\\). The solutions are constrained to those that remain bounded, resulting in discrete energy levels.\nThe matrix calculus approach to quantum mechanics: only the measureables matter The gut of Heisenberg vec attempt to derive his quantum perspective is best summarized the following phrase\nDiscard all hope of observing hitherto unobservable quantities\nIn the case of the elecctron, we dispose unobservable quantities such as the position and period in the theory but leaving behind observables such as energy in stationary states together with the associated frequencies defined only upon two variables that characterized the transition\n$$ w(n, n - \\alpha) = \\frac{1}{\\hbar} { W(n) - W(n - \\alpha) } $$\nwhich shows the algebraic structure of the frequency \\(w\\) with the transition in energy level \\(W\\).\nFrom the perspective of Heisenberg, there is not thing wrong with the classical theory, it is the classical variables have to redefine to match the algebraic structure of a quantum variable\nCarrying on with this logic, Heisenberg promote kinetic variables with the observables he defined to derive the quantum equivalent of some classical theories. For example\nA simple one-dimensional model of an atom consisting of an electron undergoes periodic motion For a state characterized by the label \\( n \\), fundamental frequency \\( \\omega(n) \\) and coordinate \\( x(n, t) \\), ne can represent \\(x(n,t) \\) as a Fourier series\n$$ x(n,t) = \\sum_{\\alpha=-\\infty}^{\\infty}{X_{\\alpha}(n)exp[i\\omega(n)\\alpha t]} $$\nThen, Heisenberg asks the question: \u0026lsquo;how is the quantity \\(x(t)^{2}\\)\u0026rsquo; to be represented?\u0026rsquo;. In classical theory, it would be\n$$ [x(t)]^{2} = \\sum_{\\alpha}{\\sum_{\\gamma}{X_{\\alpha}(n)X_{\\gamma}(n)e^{i\\omega(n)(\\alpha + \\gamma)t}}} = \\sum_{\\beta}{Y_{\\beta}(n)e^{i\\omega(n)\\beta t}}$$\nIn classical theory, the frequencies simply add up. The resulting algebric structure is then\n$$ Y_{\\beta}(n) = \\sum_{\\alpha}{X_{\\alpha}(n)X_{\\beta - \\alpha}(n)} $$\n$$ \\omega(n)\\beta = \\omega(n)\\alpha + \\omega(n)(\\beta - \\alpha) $$\nNote that these quantities could not be combined in the same way in the case of quantum, one crucial different is how the frequencies would combine like\n$$ \\omega(n, n-\\alpha) + \\omega(n-\\alpha, n-\\beta) = \\omega(n, n-\\beta) $$\nHence, promoting these varibales to quantum compatibles, yield the following algebraic relation\n$$ Y(n, n-\\beta) = \\sum_{\\alpha}{X(n, n-\\alpha)X(n-\\alpha, n-\\beta)} $$\nAlso known as the Heisenberg\u0026rsquo;s law for multiplying transition amplitude together. One profound characterisitics is that these promoted quantities don\u0026rsquo;t commute. These non-commutativity define the Heisenberg algrebra that could essentially allow us to solve discrete energy eigenvalues.\nLet\u0026rsquo;s see how this commutation relation be applied define the momentum and position operator to be \\(p = i\\hbar \\nabla \\) and \\( q = x \\). Its communtation relation \\( [p, q] = pq - qp = i\\hbar \\) can be verified by acting on a wavefunction \\(\\psi(x)\\).\n$$ [p, q] = -i\\hbar \\frac{\\delta }{\\delta x}(x\\psi(x)) + i \\hbar x \\frac{\\delta }{\\delta x} {\\psi(x)} $$ $$ = -i\\hbar \\psi -i\\hbar x \\psi ^{\\prime} + i\\hbar x\\psi^{\\prime} = -i \\hbar \\psi = -i \\hbar $$\nIgonoring the planck constant \\(\\hbar\\) we yield the Heisenberg algebrba \\( [ p, q ] = i\\). We move a step forward defining an operator \\(a, a^{\\dagger}\\) from the Heisenberg algebra\n$$ a = \\frac{1}{\\sqrt{2}}(q+ip), a^{\\dagger} = \\frac{1}{\\sqrt{2}}(q-ip) $$\nThe communtation relation \\( [a, a^{\\dagger}]\\) known as Dirac algebra. Defining the Hermitian operator \\(N = aa^{\\dagger}\\). It could be diagonlized with eigenvalues of \\(n\\) and eigenvector \\(\\left| n \\right\\rangle \\).\nConsider the following communtation relation:\n$$ [a, N ] = aa^{\\dagger}a - a^{\\dagger}aa= (aa^{\\dagger} - a^{\\dagger}a)a = [a, a^{\\dagger}]a$$\nHence,\n$$ Na \\left | n \\right\\rangle = (aN - a) \\left | n \\right\\rangle = (n-1)a \\left |n \\right\\rangle$$\nThus \\(a \\left | n \\right\\rangle\\) is an eigenstate of \\( N \\) with eigenvalue equal to \\((n-1)\\).\nWrite the state \\( a\\left | n \\right\\rangle = C_{n} \\left | n-1 \\right\\rangle \\) with \\(C_{n}\\) some normalization factor. Hermitian conjuating both side yields \\( \\left\\langle n \\right| a^{\\dagger} = \\left\\langle n-1 \\right| C_{n}^{\\ast}\\). Squaring \\(a\\left| n \\right\\rangle\\)\n$$ \\left\\langle n \\right| a^{\\dagger}a \\left | n \\right\\rangle = \\left\\langle n\\right| N \\left| n \\right\\rangle = n = \\left\\langle n-1 \\right | |C_{n}^{2}| \\left | n-1 \\right\\rangle$$\nHence, the normalization factor \\(C_{n} = \\sqrt{n}\\) and the recursion relation\n$$ a \\left | n \\right\\rangle = \\sqrt{n-1} \\left| n -1 \\right\\rangle$$\nand for \\(a^{\\dagger}\\), simiarly\n$$ a^{\\dagger} \\left | n \\right\\rangle = \\sqrt{n+1} \\left| n + 1 \\right\\rangle $$\nFor \\(n\\) being a positive integer, it suggests there exists an eigenvector \\( a\\left| 1 \\right\\rangle = \\left| 0 \\right\\rangle \\) and unbounded upper eigenvector. There are two observation to be made from this creation and annihilation operators approach.\nA inifinite dimension matrix: Hilbert space The Dirac algebra can be relaized in terms of an infinite-dimensional matrix \\(A\\) with element \\(A_{n-1, n} = \\left\\langle n-1 \\right | a \\left| n \\right\\rangle \\) above the diagonal. So, does the operators \\(p\\) and \\(q\\) in the Heisenerg algebra. The operators in quantum mechanics live in the infinite dimensional space which we call it the Hilbert space.\nTop-down derivation of harmonics potential The eigenvalues of the harmonics potential is given by \\(\\frac{1}{2}(N + 1)\\). Starting from here and assuming we do not know the functional structure of the harmonics potential,\n$$ H = \\frac{1}{2}(N + 1) = \\frac{1}{2}a^{\\dagger}a + \\frac{1}{2} = \\frac{1}{2}\\left( (q-ip)(q+ip) + 1 \\right) $$ $$ H = \\frac{1}{2}(p^{2} + q^{2}) = -\\frac{1}{2} \\frac{d^{2}}{dx^{2}} + \\frac{1}{2}x^{2}$$\nPreciesely the Hamiltonian of the harmonic oscillator.\nNaturally, the next question we ask is if this method is general. Meaning that for any particular system with \\(k\\) degree of freedom, with matrix \\( q_{1},\u0026hellip;,q_{k},p_{1},\u0026hellip;,p_{k} \\) that satisfies the communitation rules. And for these matrices, we always find a matrix \\(H(q_{1},\u0026hellip;,q_{k},p_{1},\u0026hellip;,p_{k})\\) that could be diagonlized. In order to compare the Schrodinger wavefunction formalism and the matrix theory, this will be our starting point to transform these two distinct interpretation into one coherent quantum picture.\n( Citation: Aitchison,\u0026#32;MacManus \u0026amp; al.,\u0026#32;2004 Aitchison,\u0026#32; I.,\u0026#32; MacManus,\u0026#32; D.\u0026#32;\u0026amp;\u0026#32;Snyder,\u0026#32; T. \u0026#32; (2004). \u0026#32;Understanding heisenberg’s ’magical’ paper of july 1925: A new look at the calculational details. ) Equivalency of these two methods Solving the eigenvalue problem\n\\(F_{z}\\) and \\(F_{\\Omega}\\) space and Hilbert space\nIn a nutshell, so far we have introduce the Schrodinger wavefunction interpretation of quantum system characterized by the Schrodinger equation\n$$ \\hat{H} \\psi(q_{1},\u0026hellip;,q_{k}, p_{1},\u0026hellip;,p_{k}) = E \\psi(q_{1},\u0026hellip;,q_{k}, p_{1},\u0026hellip;,p_{k})$$\nAnd we demonstrate the matrix method first by how Heisenberg initiate its thought on promoting the classical theory to matrix and found out that the commutation relation between observables. By an example of the communtation relation \\([p, q] = i\\) and a diagonizable matrix \\(H(p, q)\\), we were able to find out the inifinite set of eigenvalues and eigenvector that agree nicely with the wavefunction methods.\nTo show how these two methods compare to each other, we first transform the matrix method into a equivalent math problem of solving eigenvalues and eigenvectors. Subsequently we compare formalism and their math representation.\nMatrix method? eigenvalues problem in disguise! First, seek the matrices \\( q_{1},\u0026hellip;,q_{k},p_{1},\u0026hellip;,p_{k} \\) that satisfy the commutation rules. And combined to give a matrix\n$$ \\bar{H} = H(\\bar{q_{1}},\u0026hellip;,\\bar{q_{k}},\\bar{p_{1}},\u0026hellip;,\\bar{p_{k}}) $$\nwould not be a diagonal matrix. The diagonalized form could be obtained by similarity transformation\n$$ q_{i} = S^{-1}\\bar{q_{i}}S, \\quad p_{i} = S^{-1}\\bar{p_{i}}S $$\nThe communtation relation will carry over, to see this\n$$ [q, p] = S^{-1}\\bar{q}SS^{-1}\\bar{p}S - S^{-1}\\bar{p}SS^{-1}\\bar{q}S = S^{-1} [\\bar{q}, \\bar{p}] S$$\nHence, \\(\\bar{H}\\) goes over into \\( H \\) with \\(S^{-1}\\bar{H}S = H\\)\nThe only requirement from the above relation on \\(S\\) is that \\( S^{-1}\\bar{H}S \\) be a diagonal matrix where \\( \\bar{H} \\) is given.\nLet the matrix \\( \\bar{H} \\) have the elements \\(h_{\\mu \\nu}\\). the desired matrix \\(S \\) has element \\(S_{\\mu\\nu}\\), and the diagonal matrix \\(H\\) has element \\(w_{\\mu}\\), writing the matrix multiplication explicitly we got\n$$ \\sum_{\\nu}{h_{\\mu\\nu} s_{\\nu\\rho}} = w_{\\rho}\\cdot s_{\\nu\\rho} $$\nWe recognize that \\(s_{\\mu\\rho} \\) is the column vector \\( s_{1\\rho}, s_{2\\rho},\u0026hellip; \\). Hence, to specify the transformation \\(S\\) is equivalent in solving eigenvalues problem which runs as follows:\n$$ \\sum_{\\nu}{h_{\\mu\\nu}x_{\\nu}} = \\lambda \\cdot x_{\\mu} \\quad \\quad (\\mu = 1, 2, \u0026hellip;) $$\nThese set of eigenvalues and eigenvectors are essentially the only solutions. The knowledge of \\( S, H \\) determine all the solutions of the eigenvalue problem, but conversly, we can also determine \\( S, H \\) as soon as we have solved the eigenvalue problem completely.\nThe fundamental problem of the matrix theory is then the solution of the eigenvalue equation\n$$ \\sum_{nu}{h_{\\mu\\nu}x_{\\nu}} = E \\cdot x_{\\mu} \\quad \\quad (\\mu = 1, 2, \u0026hellip;) $$\nThe remaining task for us is to check that how this transformation to eigenvalues problems matches with the wavefunction formulism.\nWavefunction looking alike but not the same The defining charactersitics of the wave equation is the following\n$$ \\hat{H}\\psi(q_{1}, \u0026hellip;, q_{k}) = \\lambda \\psi(q_{1}, \u0026hellip;, q_{k}) $$\nIn which \\(H\\) is the Hamiltonian differential operator. We seek all solutions \\(\\psi(q_{1},\u0026hellip;,q_{k})\\) and \\( \\lambda \\). At first sight, this is very similar to what was required in the eigenvalue equation, which we could regard it as a function \\(x_{\\nu}\\) of the \u0026ldquo;discontinuous\u0026rdquo; variable \\(\\nu\\) which ranges over \\(1, 2,\u0026hellip;\\) corresponds to the function \\(\\psi(q_{1}, \u0026hellip;, q_{k})\\) with the \u0026ldquo;continuous\u0026rdquo; variables \\(q_{1}, \u0026hellip;, q_{k}\\), with \\(\\lambda\\) playing the same role each time.\nUpon further inspection on how these two objects transform, they do differ in a subtle way. The matrix method leads to a vector representation of the quantum state.\n$$ x_{\\mu} \\rightarrow \\sum_{\\nu}{h_{\\mu\\nu}x_{\\nu}} $$\nBut how does the wavefunction transform? We know probability is conserved in a closed quantum system and hence quantum state must undergo unitary transformation to conserve the probability.\nTo show, we first recall the norm is defined for the wavefunction\n$$ \\int{\\psi^{\\ast}(\\vec{r})\\psi(\\vec{r})d(\\vec{r})} = 1 $$\nWe expect that under transformation the norm is preserved or equivalently the total probability is conserved\n$$ \\int{\\bar{\\psi}^{\\ast}(\\vec{r})\\bar{\\psi}(\\vec{r})d\\vec{r}} = 1 $$\nLet\u0026rsquo;s define the one dimension representation of the \\(U(1)\\) be \\(e^{i\\vec{r}\\cdot\\vec{p}}\\). Then, under unitary transformation, the norm becomes\n$$ \\int{\\psi^{\\ast}(\\vec{r})e^{-i\\vec{r}\\cdot\\vec{p}}e^{i\\vec{r}\\cdot\\vec{p}}\\psi(\\vec{r})d\\vec{r}} = 1 $$\nAlso we recall that \\(\\psi(\\vec{r}) \\propto \\int{\\phi(\\vec{p})e^{i\\vec{r}\\cdot\\vec{p}}d\\vec{p}}\\). The wavefunction transform into different basis by fourier method.\nWe can indeed draw a parallel between these function. The first being vector space with well defined norm. The Schrodinger picture could also be understood as a vector with orthogonality vector and its weight. These properties are known as the Hilbert space.\n( Citation: Neumann,\u0026#32;1955 Neumann,\u0026#32; J.\u0026#32; (1955). \u0026#32; Mathematical foundations of quantum mechanics. \u0026#32; Princeton University Press.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=JLyCo3RO4qUC ) Final Remark In the spirit of Feynnman, it will be a waste of time to put effort in making different interpretation of the quantum derivation. Nevertheless, it is still a great practice to be more thoroughly understand the historical context and mathematical motivation. Especially, when most quantum textbook often introduces these two concepts at its convience and yet never compare how these two methods differ. For it might be crucial in understanding what appraoch might be more appropriate in solving a particular quantum system.\nTo emphazie one more important aspect of such attempt to compare methods, it is that a new era of quamtum computation which heavily relies on the John Von Neumann density matrix representation of the quantum state. For this particular representation, operation of quantum mixed state and pure state is easily computed with mathematical convinence. And the ponding question of how the matrix thoery and wavefunction approach settle into one unify picture of microscopic phenomena is what drive Von Neumann to derive a representation that is irrevelent on how it\u0026rsquo;s presented.\nWe neglect some eariler motivation from Schrodinger and Heisenberg because in the development stage of a brand new theory it often took a lot of guess work to keep pushing.\nSome aspects are being abbrivated such as Schrodinger\u0026rsquo;s thought on the relevence of action principle to the formulation of quantum mechanics. But it was later developed by Dirac and Feynnman that the quantum version of the action principle could be devised starting from a notion of summing of all possible paths along the initial and final states but that\u0026rsquo;s another topic.\nBiblography Zeng (2008) Zeng,\u0026#32; J.\u0026#32; (2008). \u0026#32; 量子力学教程. \u0026#32; 科学出版社.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=foQcPwAACAAJ Aitchison,\u0026#32; MacManus\u0026#32;\u0026amp;\u0026#32;Snyder (2004) Aitchison,\u0026#32; I.,\u0026#32; MacManus,\u0026#32; D.\u0026#32;\u0026amp;\u0026#32;Snyder,\u0026#32; T. \u0026#32; (2004). \u0026#32;Understanding heisenberg’s ’magical’ paper of july 1925: A new look at the calculational details. Neumann (1955) Neumann,\u0026#32; J.\u0026#32; (1955). \u0026#32; Mathematical foundations of quantum mechanics. \u0026#32; Princeton University Press.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=JLyCo3RO4qUC ","permalink":"https://htsod.github.io/posts/wave_particle/","summary":"\u003c!-- raw HTML omitted --\u003e\n\u003ch2 id=\"anyone-is-feeling-weird\"\u003eAnyone is feeling weird?\u003c/h2\u003e\n\u003cp\u003eThe contradiction between classical physics and microscopic phenomena is one of the most fascinating episodes in the history of science, reshaping our fundamental understanding of waves and particles. To grasp the weirdness of \u003cstrong\u003ewave-particle duality\u003c/strong\u003e, let’s start with a simple analogy.\u003c/p\u003e\n\u003cp\u003eImagine shooting bullets at a wall with two equally spaced gaps. As expected, the bullets passing through each gap will behave independently, forming two distinct patterns on a measurement panel behind the wall. Each pattern would look like a Gaussian distribution centered around the corresponding slit. The resulting measurement would be a straightforward combination of these two distributions:\u003c/p\u003e","title":"Quantum Mechanical Historian"},{"content":"Entropy, Order Parameters and Complexity What is statistical mechanics? Ensemble How to connect microscopic law with macroscopic phenomenon? The concept of ensemble provides a method that connects the two. Treating a large system(macroscopic) as collection of similarly prepared systems(microscopic).\nEntropy Entropy to be defined as a function of probability distribution \\(p_{i}\\) must satisfy the following:\nMaximum at \\(\\frac{1}{p_{i}}\\) Minimum at \\(p_{i} = 0 , S = 0\\) Minimum at \\(p_{i} = 1, S = 0\\) The unique function that satisfies the above requirement is \\(S=-p_{i}\\log{p_{i}}\\), giving rise to the information interpretation of entropy. From the first requirement, we could see that entropy is maximized when the distribution is more even, or in other words, more mixed, leading to the disorder interpretation of entropy. If entropy is zero, the probability distribution is either \\(0\\) or \\(1\\). Then, if the value of entropy is the only thing we know about the system, we could easily reproduce the system distribution with certainty. As entropy increases, it will be less likely that we could reproduce the system from scratch, making the system irreversible. And this gives rise to the reversibility interpretation of entropy.\nQuantum Statistical Mechanics Quantum mechanics is the law that governs microscopic evolution and particles type. Whereas in everyday life where temperature is sufficiently high, we do not have to worry about quantum mechanical effect. The underlying reason is that the asymetrical states that are created by quantum mechanics effect is thermalized to equally occupied states. So, in sufficiently high temperature, we could treat particles as ideal gas that have no internal structure.\nThe reverse is true. As we cool object, the states might settle into one of the asymetrical states and shows bewildering behavior.\nMonte Carlo It allow the computer to find ensemble averages in systems far too complicated to allow analytical evaluation.\nPhases Different phases are categorized by different symmetries. Matters with different symmetries cannot cross by perturbation theory. So far, there are two recognized way for matter to transit from one state to another. Namely the abrupt phase transition and continous phase transition.\nFluctuations and correlations How a system reponse is related to the correlation function of the system. THe correlation function measure the alignment of state within the system and it condensed the information more compactly.\nAbrupt phase transition By the name suggests, it happens when there is a discontinouity at the first derivative of the free energies because the phase boundary must have equal free energy but above and below it is a different free energy function.\nCriticality The second type of phase changes is by continuous phase transition. This happens when the symmetries of matter change. At critical temperature where the transition occurs, the system fluction is singular at the zero frequency vibration mode. At this point of transition, the system is self-similar. This phenomena is universal across different physical system.\nRandom walks and emergent properties Random walks is defined as taking a random steps in a given manifold randomly for every time step. This simple microscopic evolution rule\nTemperature and equilibrium Why do systems approach equilibrium?. When one of my classmates asked this question in a highschool chemistry class, I was astonished by how naturally we took in the concept that system eventually reaches equilibrium but never asked why. This inquiry of equilibrium had stucked in my head for quite a while until reading upon a statistical mechanics textbook which offers a elegant explanation to equilibrium. The short answer is that the states of equilibrium is much more probable than some other non-equlibrium states for microcanonical ensembles. One could imagine a system dynamics as flow in a network diagram with each nodes representing a possible state.\nAs time proceeds, the flow on each node has probability to evolve into some other states and will eventually reach a time-independent state which we called it equilibrium. Formally speaking, when we say a system has reached a state of equilibrium, we mean that the observable of the time average and the ensemble averages equal. Alternatively, no matter how the flow initially biased towards a particular set of states, as time proceeds, it eventually becomes uniform across all the possible states (a microcannonical ensemble). Noting that the above diagram has a equal number of nodes at the start and at the end. This is because the system is isolated and the total possible states remain unchanged.\nTo illustrate how the above model could be used to explain why a microcannonical system will reach equilibrium eventually,imagining mixing two types of particles with a total particle number of N. Initially, \\(\\frac{N}{2}\\) of particle A and \\(\\frac{N}{2}\\) of particle B each occupies half of the box with a partition in between.\nIgnoring the momentum degree of freedom, the possible states are the volume configuration \\( \\Omega_{unmixed} = \\frac{((V/2)^{N/2})^{2}}{(N/2)!(N/2)!} = \\frac{1}{2^{N}} \\frac{(V)^{N}}{(N/2)!(N/2)!} \\). The nominator states that there is \\( (V/2)^{N/2} \\) ways of configurations allowed for \\(N/2\\) particle in a volume \\(V/2\\). The denominator states that in those indistinguishable \\(N/2\\) particle A and \\( N/2 \\) particle B, they can freely exchange their states without changing the configuration of the system. Now by removing the partition, a total of N particle could fill the entire volume. The mixed state becomes \\( \\Omega_{mixed} = \\frac{(V)^{N}}{(N/2)!(N/2)!} = 2^{N} \\Omega_{unmixed} \\). Provided N is a large number of order \\( \\sim 10^{23} \\). The mixed state is much more likely than the unmixed state by simply out numbering the possibles state of an un mixed state. Hence, as the system evolves (by how we do not care), it is much more likely to fill the mixed states than the unmixed state reaching equilibrium.\nFraming this mixing process with the network model we defined above. Before mixing, we have \\( \\Omega_{unmixed} \\) states to start with. As we remove the partition, the system is no longer isolated and as a result the total number of states have increased to \\( \\Omega_{mixed} = 2^{N} \\Omega_{unmixed} \\). Because the flow is distributed uniformly across all possible states in equilibrium, the mixed states are far more likely than the unmixed states.\nThen, how likely the system will remain in the non-equlibrium unmixed state after mixing? With a crazy small probability of \\(P_{unmixed} = \\frac{1}{2^{N}} \\). Take \\( N = 10 \\), \\( P_{unmixed} = 0.001 \\). Not to mention that N usually of order \\( \\sim 10^{23} \\)\nPhase-space dynamics and ergodicity One might consider further and ponder what kind of system will eventually reach equilibrium where macroscopic observable remain statistically fixed except for rare thermal fluctuation. Or equivalently, for what kind of system does its time average behavior and ensemble behavior equal. Let\u0026rsquo;s start with a most common system. A classical \\(N\\) particle system in which its evolution is descirbed by its Hamiltonian. \\( H(P,Q) = \\sum_{\\alpha}{p_{\\alpha}^{2}/2m_{\\alpha} + U(q_{1}, \u0026hellip;, q_{3N})} \\). We want to study how Hamiltonian evolution will modify the \\(\\rho(q_{1},\u0026hellip;,q_{3N},p_{1},\u0026hellip;,p_{3N})\\) \\(6N\\) dimensional phase space density distribution.\nConsider the total time derivative on \\(\\rho\\)\n$$ \\frac{d \\rho}{dt} = \\frac{\\partial \\rho}{\\partial t} + \\vec{\\nabla} \\cdot \\vec{J} $$\nwhere \\(\\vec{J} = (\\rho \\dot{P}, \\rho \\dot{Q}\\)) is the phase space probability current. For probability to conserve, total derivative of \\(\\rho\\) must vanishes giving the continuity equation\n$$ \\frac{\\partial \\rho}{\\partial t} = -\\sum_{\\alpha=1}^{3N}{\\frac{\\partial \\rho}{\\partial q_{\\alpha}}q_{\\alpha} + \\frac{\\partial q_{\\alpha}}{\\partial q_{\\alpha}}\\rho_{\\alpha} + \\frac{\\partial \\rho}{\\partial p_{\\alpha}}p_{\\alpha} + \\frac{\\partial p}{\\partial p_{\\alpha}}\\rho_{\\alpha}} $$\nSo far we did the discussion is completely general to the \\(6N\\)-dimensional system. Observing the terms above we see two of them are rather strange looking \\( \\frac{\\partial q_{\\alpha}}{\\partial q_{\\alpha}}\\rho_{\\alpha} \\) and \\( \\frac{\\partial p}{\\partial p_{\\alpha}}\\rho_{\\alpha} \\). Indeed, for Hamiltonian system these term cancel out leading to the Liouville\u0026rsquo;s theorem\n$$ \\frac{\\partial \\rho}{\\partial t} = -\\sum_{\\alpha=1}^{3N}{\\frac{\\partial \\rho}{\\partial q_{\\alpha}}q_{\\alpha} + \\frac{\\partial \\rho}{\\partial p_{\\alpha}}p_{\\alpha} = 0} $$\nFor folks that familiar with fluid dynamics this is like saying fluid only flow around but cannot be compressed.(changing its density by going somewhere in space) In this case, the \\(6N\\)-dimensional phase space behaves as the incompressible fluid; some states become less likely only by \u0026ldquo;flowing\u0026rdquo; its likeliness to its neighbor states.\nEntropy Free energies Ever being involved in drawing a color ball from a mysterious box and winning a price only when a certain color or combination are drawn? Statistical mechanics from another perspective is fairly similar to this concept of drawing color ball except that some functional constraints have been applied to the color ball ensuring that this model is compatible with some physical process in interest.\nIn microcanonical ensemble, the states of the system are labelled by its position and momentum, which together gives the position and momentum dependent energy \\(E_{s} = \\frac{p^{2}}{2m} + U(r)\\) of that state.\nQuantum statistical mechanics Ongoing\nBibliography Bibliography called, but no references ","permalink":"https://htsod.github.io/review/statistical_mechanics/","summary":"\u003ch2 id=\"entropy--order-parameters-and-complexity\"\u003eEntropy,  Order Parameters and Complexity\u003c/h2\u003e\n\u003ch3 id=\"what-is-statistical-mechanics\"\u003eWhat is statistical mechanics?\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eEnsemble\u003c/em\u003e\nHow to connect microscopic law with macroscopic phenomenon? The concept of ensemble provides a method that connects the two. Treating a large system(macroscopic) as collection of similarly prepared systems(microscopic).\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eEntropy\u003c/em\u003e\nEntropy to be defined as a function of probability distribution \\(p_{i}\\) must satisfy the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eMaximum at \\(\\frac{1}{p_{i}}\\)\u003c/li\u003e\n\u003cli\u003eMinimum at \\(p_{i} = 0 , S = 0\\)\u003c/li\u003e\n\u003cli\u003eMinimum at \\(p_{i} = 1, S = 0\\)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe unique function that satisfies the above requirement is \\(S=-p_{i}\\log{p_{i}}\\), giving rise to the information interpretation of entropy. From the first requirement, we could see that entropy is maximized when the distribution is more even, or in other words, more mixed, leading to the disorder interpretation of entropy. If entropy is zero, the probability distribution is either \\(0\\) or \\(1\\). Then, if the value of entropy is the only thing we know about the system, we could easily reproduce the system distribution with certainty. As entropy increases, it will be less likely that we could reproduce the system from scratch, making the system irreversible. And this gives rise to the reversibility interpretation of entropy.\u003c/p\u003e","title":"Study Notes on Statistical Mechanics"},{"content":"Preview This blog provides a concise overview of some key noise-resilient, intermediate-scale quantum algorithms, designed for a general audience. We\u0026rsquo;ll first explore the core mechanics of these algorithms, followed by their applicability to existing classical counterparts. Lastly, we\u0026rsquo;ll discuss the hardware requirements necessary to implement these algorithms, with a focus on managing noise in quantum systems.\nVariational Quantum Eigenvalue (VQE) With the quantum hardware progressing, promising quantum algorithm has been devised to harness the exotic nature of quantum computer. Notably the Shor\u0026rsquo;s algorithm and Grover search algorthm which demonstrate significant improvement over classical computer. However, those algorithms require quantum resources that are far-fetching in today quantum hardware standard. Therefore, there are several quantum algorithms that have been devised to be sufficiently useful in the noise Intermediate-scale quantum(nisq) stage of quantum information industry. One prominent algorithm is variational quantum eigensolver. It is based on the variational principle which says that an approximation quantum state that is close to the ground state of a quantum system yields a sufficiently close solution to the eigenvalues of the ground state.\n$$ \\left \\langle \\psi(\\theta) \\right | H \\left | \\psi(\\theta)\\right\\rangle = \\lambda_{approx} \\ge \\lambda_{g} = \\left \\langle \\psi_{g} \\right | H \\left | \\psi_{g} \\right\\rangle$$\nHere we parameterized the state $\\psi(\\theta)$ to be trained on a classical computation iteratively by measuring the eigenvalue using a quantum circuit. By doing so we expect the eigenvalue would close up the gap with the true ground state of the Hamiltonian. Gearing with the general idea of how it works, here we list the motivation to develop VQE:\nIs it theoretically faster than classical computer?\nWhat kind of realistic problem can it solve?\nWe don\u0026rsquo;t know yet it is faster or not but solving for the ground state for a state vector is a difficult task for a classical computer.\nAs for the second question, it was said that chemical interaction happens quantum mechanical and hence the simulation must also be done quantum mechanically. VQE so far has been apply for solving the ground state energy or excited of a molecular configuration. Though it does not limit to simulation problem, for problem that could map to this structure could be used equally well.\nHere are the steps to implement\nEncode the problem Hamiltonian into circuit element\nMapping the problem state vector to a parameterized state living in the \\(2^{n}\\) computational basis\nMeasure the energy eigenvalue\nUse classical optimizer to minimize the eigenvalue by varying the parameters.\nrepeat step 1 to step 5 until it saturates\nIn the case of molecular simulation where the system in interest is based on fermions, the encoding could done by Jordan-Wigner or Brivate-\nQuantum Approximation Optimization Algorithm (QAOA) Ongoing\nBibliography called, but no references ","permalink":"https://htsod.github.io/posts/nisq/","summary":"\u003ch2 id=\"preview\"\u003ePreview\u003c/h2\u003e\n\u003cp\u003eThis blog provides a concise overview of some key noise-resilient, intermediate-scale quantum algorithms, designed for a general audience. We\u0026rsquo;ll first explore the core mechanics of these algorithms, followed by their applicability to existing classical counterparts. Lastly, we\u0026rsquo;ll discuss the hardware requirements necessary to implement these algorithms, with a focus on managing noise in quantum systems.\u003c/p\u003e\n\u003ch2 id=\"variational-quantum-eigenvalue-vqe\"\u003eVariational Quantum Eigenvalue (VQE)\u003c/h2\u003e\n\u003cp\u003eWith the quantum hardware progressing, promising quantum algorithm has been devised to harness the exotic nature of quantum computer. Notably the Shor\u0026rsquo;s algorithm and Grover search algorthm which demonstrate significant improvement over classical computer. However, those algorithms require quantum resources that are far-fetching in today quantum hardware standard. Therefore, there are several quantum algorithms that have been devised to be sufficiently useful in the noise Intermediate-scale quantum(nisq) stage of quantum information industry. One prominent algorithm is variational quantum eigensolver. It is based on the variational principle which says that an approximation quantum state that is close to the ground state of a quantum system yields a sufficiently close solution to the eigenvalues of the ground state.\u003c/p\u003e","title":"NISQ Quantum Algorithm"},{"content":"Preview Network theory or Graph theory (in computer science terminology) is the study of nodes that are connected by edges. At first sight, this simple reprsentation of information does not seem physically useful. However, as it turns out from a historical point of view, it has a wide range of application ranging from social science and biology. Why a simple model could be physically useful? To elaborate, we take a slight detour of explaining how physical how one could understand a physical event.\nPhysics unravel the fundamental interaction between matter. As those matter adds up, some collective behavior and complexity arises that were unpredictable only by knowing the fundamental interactions. Even if we master quantum mechanics, we barely could predict any phenomena in social science even though people is made up of matter. What about we delegate this task of prediction to a super computer? In which every bit of physical detail is encoded in terms of binary and simulate the world with a giantic processor. That\u0026rsquo;s a impossibility needless of explanation. The hope is that not every pieace of microscopic interaction is usefull and contribute to the macroscopic observable. For the irrelevent degree of freedom that does not contribute to the collective behavior of a larger system, we could coarse grain the reality into something simplier and yet captures its essential property. This is where network theory comes in the play. We made some drastic simplification to the reality by assuming that the system in interest has indistinguishable identity calling it nodes. And we are only interested in its connectivity to their counter parts.\nStarting from this applicabilty of network, the study of network can be summarized.\nMaking the simple network more complicated just to incorporate the relevence degree of freedom. Along in this direction, the concept of weighted and directed netork is being introduced for a more intricated interaction. Measurement scheme to qunatity the structure of a given network. For examples, clustering coefficient, centrality and shortest distance. Modelling collective dynamics of many-body system. Example include synchronization. Study of the ensemble of network model given by constraints on its structure. Example include random network, scale free network 1. Adding Details 2. Measurement Scheme 3. Dynamics of Network 4. Adding Constraints ","permalink":"https://htsod.github.io/review/network/","summary":"\u003ch2 id=\"preview\"\u003ePreview\u003c/h2\u003e\n\u003cp\u003eNetwork theory or Graph theory (in computer science terminology) is the study of nodes that are connected by edges. At first sight, this simple reprsentation of information does not seem physically useful. However, as it turns out from a historical point of view, it has a wide range of application ranging from social science and biology. Why a simple model could be physically useful? To elaborate, we take a slight detour of explaining how physical how one could understand a physical event.\u003c/p\u003e","title":"Study Notes on Network Theory"},{"content":"Preview If one struggle to convince themselves the sanity of quantum mechanics, the best advice to them is to move on and put yourself into practical question and work out the math. That\u0026rsquo;s the core spirit of this reivew note about. All we need to know is the necessary axioms which were verified long ago, and then to make use of these axioms to draw meaningful observation on the theory itself or practical problems to draw in more intuition.\nAxioms of Quantum Mechanics: Get to the points Rule 1: Hilbert space A dynamical system corresponds to a Hilbert space in such a way that a definite state of the system corresponds to a definite ray in the space.\na state \\(\\left| u \\right\\rangle \\)if it corresponds to the ray in the direction of vector \\(\\left| u \\right\\rangle\\) complex factor and phase factor don\u0026rsquo;t change its state linear combination of definite state produces another possible state linear superposition principle relative phase between states matters An isolated quantum mechanical system can evolve with time unitarily. The evolution is continuous and causal.\nRule 2: Time evolution An isolated quantum state evolves continously and casually in time by a unitary operator U.\n$$ \\left| u(t) \\right\\rangle = U(t, t_{0}) \\left | u(t_{0}) \\right\\rangle $$\nwhere \\( U(t, t_{0}) = e^{\\left[-\\frac{i}{\\hbar}\\int_{t_{0}}^{t}H(t^{\\prime})dt^{\\prime}\\right]}\\)\nStarting from this axiom, one can derive the Schrodinger equation which we shall show.\nLet \\( t\u0026gt;t_{0} \\), then unitary evolution \\(U(t, t_{0})\\) of the wavefunction \\( u(t_{0})\\) to \\(u(t)\\) can be stated as the following\n$$ \\left| u(t) \\right\\rangle = U(t, t_{0})\\left| u(t_{0}) \\right\\rangle$$\nIn Lie\u0026rsquo;s approach, we try to cover the unitary transformation with infinitestimal change from the identity, hence infinitestimal change of unitary operation can be written as\n$$ U(t_{0} + \\delta t, t_{0}) = I + K \\delta t $$\nFrom the definition of unitary, \\( U \\) must satisfy \\( U^{\\ast}U = I \\), which yields\n$$ U^{\\ast}U = (I + K)^{\\ast}(I+K)= I + K^{\\ast} + K = I $$\n$$ K^{\\ast} = -K $$ Requiring , $K$ to be antihermitian. We could as well write \\(K = iH\\) and \\( H \\) to be hermitian.\nTo cover the time evolution up to \\(t\\), we carry the infinitestimal operations up to \\(N\\) times, and taking \\( N \\) to be infinte.\n$$ U(t) = \\lim_{N\\rightarrow \\infty}(U(t/N))^{N}= \\lim_{N\\rightarrow \\infty}\\left(I - iH \\frac{t}{N}\\right)^{N}= e^{-iHt} $$\nNow we could rewrite the evolution of the wavefunction to derive the Schrodinger equation,\n$$ U\\left| u(t) \\right\\rangle = \\left( I - \\frac{i}{\\hbar} H \\delta t \\right) \\left| u(t) \\right\\rangle = \\left | u(t+\\delta t) \\right\\rangle $$\n$$ H\\left|u(t) \\right\\rangle = i\\hbar \\frac{\\delta \\left|u(t)\\right\\rangle}{\\delta t} $$\nAs promised.\nRule 3: Observables Each observable of a system is associated with a Hermitian operator on the Hilbert space of the system. We assume that the eigenstates of each observable form a complete set.\nTo get a intuitive picture of this axiom, we first note that the statistical properties of the wavefunction allows us to weight the contribution of the wavefunction on to a obervable. Stating the the statistical properties:\nProbability distribution sum to one $$ \\int^{\\infty}_{-\\infty}{\\psi^{\\ast}(x) \\psi(x)dx } = 1 $$\nGiven observable \\( O(x) \\), $$ \\int^{\\infty}_{-\\infty}{\\psi^{\\ast}(x)O(x) \\psi(x)dx } = \\left\u0026lt; O(x)\\right\u0026gt; $$\nWriting in Dirac notation, \\( \\left\u0026lt; O(x)\\right\u0026gt; = \\left\\langle \\psi \\right| O(x) \\left| \\psi \\right\\rangle \\).\nHermitian conjugate both side and subtract it from its originall form\n$$ \\left\\langle \\psi \\right| O^{\\dagger}(x) - O(x) \\left| \\psi \\right\\rangle = \\left\u0026lt; O(x)\\right\u0026gt; - \\left\u0026lt; O(x)\\right\u0026gt; = 0$$\nHence, \\( O^{\\dagger}(x) = O(x)\\) is hermitian.\nThe second statement is saying that for any set of commuting observables, \\(A_{1}, A_{2},\u0026hellip; \\), the system can be expressed as the superposition of \\( \\psi = \\sum_{a}{a_{a}\\psi_{a}} \\)\nRule 4: Measurement The result of any given measurement of an observabble is an eigenvalue of the corresponding Hermitian operator.\nRule 5: Statistical The average \\( \\bar{A} \\equiv \\left\\langle A \\right\\rangle \\) of a number of measurements of \\(A\\) is\n$$ \\bar{A} \\equiv \\left\\langle A \\right\\rangle = \\frac{\\left\\langle u|A| u \\right\\rangle}{\\left\\langle u|u \\right\\rangle} $$\nWith \\( u \\) an eigenstate of \\( \\Rightarrow \\left| u \\right\\rangle = \\left| \\phi_{i} \\right\\rangle \\), \\( A \\left| \\phi_{i} \\right\\rangle = \\lambda_{i} \\left|\\phi_{i} \\right\\rangle \\) $$ \\bar{A} = \\frac{\\left\\langle \\phi_{i}|A| \\phi_{i} \\right\\rangle}{\\left\\langle \\phi_{i}|\\phi_{i} \\right\\rangle} = \\lambda_{i} \\Rightarrow \\triangle^{2} = \\left\\langle A^{2} \\right\\rangle - \\left\\langle A \\right\\rangle ^{2} $$\nWith \\( u \\) not an eigenstate of A $$ \\left| u \\right\\rangle = \\sum_{i} \\left| \\phi_{i} \\right\\rangle \\left\\langle \\phi_{i} \\right| \\left| u \\right\\rangle $$\n\\(u\\) in basic of \\( \\phi_{i} \\)\n$$ \\bar{A} = \\sum_{i, j} \\frac{\\langle u | \\phi_{i} \\rangle \\langle \\phi_{i} | A | \\phi_{j} \\rangle \\langle \\phi_{j} | u \\rangle}{\\langle u | u \\rangle} = \\frac{\\sum_{i} \\lambda_{i}|\\langle u | \\phi_{i}\\rangle |^{2}}{\\sum_{i} | \\langle u | \\phi_{i} \\rangle |^{2}}$$\n$$ \\bar{A} = \\frac{\\sum_{i} P_{i} \\lambda_{i}}{\\sum_{i} P_{i}} $$\nRule 7: Wavefunction collapse A measurement of observable \\( A \\) resulting in eigenvalue \\( \\lambda_{i} \\) projects the state vector from \\( |u\\rangle \\) to that subspace of the Hilbert space associated with \\( \\lambda_{i} \\). If the eigenvalue is nondegenerate, the subspace is just a single eiggenstate \\( \\phi_{i} \\) associated with \\( \\lambda_{i} \\). If \\( |u\\rangle \\) is already an eigenstate of \\( A \\), it\u0026rsquo;s not changed by the measreument. If \\( u \\) is not an eigenstate of \\( A \\), then in the nondegenerate case it \u0026lsquo;collapses\u0026rsquo; to \\( \\phi_{i} \\) with probability \\( |\\langle u | \\phi_{i} \\rangle |^{2} \\)\nRule2 and Rule 7 macroscopic objectification problem\nIf \\( [A, B] = 0 \\), then \\(A\\) and \\(B\\) are simultaneously diagonalized by the same unitary transformation\nIf A, B, C, \u0026hellip; form a complete set of commuting (compatible) observables then we know everythig there is to know about the steate of the system when we specify the eigenvalue of each of A, B, C, \u0026hellip; for that state\nThis is called a complete set of quantum numbers for that state\n$$ \\frac{d\\langle A \\rangle}{dt} = \\left(\\frac{ d \\langle u |}{dt}\\right) A |u\\langle + \\langle u | A \\left(\\frac{d |u \\rangle}{dt}\\right) + \\langle u | \\left(\\frac{\\delta A}{\\delta t}\\right) | u \\rangle $$\nEmploying \\( H|u\\rangle = i\\hbar \\delta_{t} |u\\rangle \\) and \\( \\langle u | H = -i \\hbar \\delta_{t} \\langle u | \\)\n$$ \\frac{d\\langle A \\rangle}{dt} = \\frac{i}{\\hbar} \\left[ \\langle u | HA | u \\rangle - \\langle u | AH | u \\rangle \\right] + \\left\\langle u \\left| \\frac{\\delta A}{\\delta t} \\right| u \\right\\rangle $$\n$$ = \\frac{i}{\\hbar} \\langle u | [A, H] | u \\rangle + \\left\\langle u \\left| \\frac{\\delta A}{\\delta t} \\right| u \\right\\rangle $$\nCarry out unitary transformation into a new basic in which \\( u \\) is a constant.\n$$ S(t, t_{0}) = U^{\\dagger}(t, t_{0}) = e^{\\left[ -\\frac{i}{\\hbar}\\int_{t_{0}}^{t} H(t^{\\prime}) dt^{\\prime} \\right]^{\\dagger}} $$\nGiving us the Heisenberg equation for uncertainty\n$$ A^{\\prime} = SAS^{\\dagger} = U^{\\dagger}AU \\Rightarrow \\frac{dA^{\\prime}}{dt} = \\frac{1}{i\\hbar} [A^{\\prime}, H] + \\frac{\\delta A^{\\prime}}{\\delta t}$$\nProbability is conserved by some kind of flow Probability conserved by flow The evolution of closed quantum system is deterministic Feynman Dirac sum over all paths To further elaborate the rule 2 of the quantum axioms, that is, a isolated quantum mechanical system will evolve unitarily, we will look at the wavefunction representation of the quantum states.\nRecall $$ \\left| u(t) \\right\\rangle = U(t, t_{0}) \\left | u(t_{0}) \\right\\rangle $$\nGiven the Schrodinger equation, nameing it eqn 1\n$$ -i\\hbar \\frac{\\partial}{\\partial t} \\psi = (-\\frac{\\hbar^{2}}{2m} \\nabla ^{2} + V) \\psi $$\nand its complex conjugate and naming it eqn 2\n$$ -i\\hbar \\frac{\\partial}{\\partial t} \\psi^{\\ast} = (-\\frac{\\hbar^{2}}{2m} \\nabla ^{2} + V) \\psi^{\\ast} $$\nMultiply Schrodinger equation from the left by \\( \\psi^{\\ast} \\) and multiply the complex conjugate of the Schrodinger equation form the left by \\( \\psi \\) and subtracting these two expression yields\n$$ i\\hbar \\frac{\\delta}{\\delta t}(\\psi^{\\ast}\\psi) = -\\frac{\\hbar^{2}}{2m} \\left(\\psi^{\\ast} \\nabla ^{2}\\psi + \\psi \\nabla ^{2} \\psi^{\\ast} \\right) $$ $$ = -\\frac{\\hbar^{2}}{2m} \\nabla \\cdot \\left(\\psi^{\\ast} \\nabla \\psi + \\psi \\nabla \\psi^{\\ast} \\right) $$\nthen in a closed integration, by Gauss theorem, the right hand side could be converted into surface integral as the following\n$$ i\\hbar \\frac{\\delta}{\\delta t} \\int_{\\tau}{\\psi^{\\ast}\\psi d\\tau} = -\\frac{\\hbar^{2}}{2m} \\oint_{S}{\\left(\\psi^{\\ast} \\nabla \\psi + \\psi \\nabla \\psi^{\\ast} \\right) \\cdot d\\vec{S}} $$\nlet \\( \\rho = \\psi^{\\ast}\\psi \\) and \\(\\vec{j}= \\psi^{\\ast} \\nabla \\psi + \\psi \\nabla \\psi^{\\ast} \\), then equation becomes the familar continuity equation in fluid dynamics\n$$ \\frac{\\delta}{\\delta t} \\rho + \\vec{\\nabla} \\cdot \\vec{j} = 0$$\nFor \\( \\rho = \\psi^{\\ast} \\psi \\), we have a fairly good intuition about it, however, the flow term is bit more tricky.\nBibliography Commins (2014) Commins,\u0026#32; E.\u0026#32; (2014). \u0026#32; Quantum Mechanics An Experimentalist’s Approach (1). \u0026#32; Cambridge University Press. Zee (2016) Zee,\u0026#32; A.\u0026#32; (2016). \u0026#32; Group Theory in a Nutshell for Physicists (1). \u0026#32; Princeton University Press. Michael A. Nielsen (2010) Michael A. Nielsen,\u0026#32; I.\u0026#32; (2010). \u0026#32; Quantum computation and quantum information. \u0026#32; Cambridge University Press. Griffiths (1995) Griffiths,\u0026#32; D.\u0026#32; (1995). \u0026#32; Introduction of quantum mechanics. \u0026#32; Prentice Hall, Inc.. ","permalink":"https://htsod.github.io/review/quantum_mechanics/","summary":"\u003ch2 id=\"preview\"\u003ePreview\u003c/h2\u003e\n\u003cp\u003eIf one struggle to convince themselves the sanity of quantum mechanics, the best advice to them is to move on and put yourself into practical question and work out the math. That\u0026rsquo;s the core spirit of this reivew note about. All we need to know is the necessary axioms which were verified long ago, and then to make use of these axioms to draw meaningful observation on the theory itself or practical problems to draw in more intuition.\u003c/p\u003e","title":"Study Notes on Quantum Mechanics"},{"content":"Relativity\u0026rsquo;s action principle constrains how light and matter interact within spacetime. By placing the potential term either inside or outside the action square root, we derive the familiar interactions of gravity or electromagnetism between matter. This post offers a top-down view of electromagnetism\u0026rsquo;s derivation from these fundamental principles.\nRelativistic Action To incorporate relativistic effects, the action is written as:\n$$ S = -m \\int{ \\sqrt{-\\eta_{\\mu \\nu} dx^{\\mu} dx^{\\nu}} } = -m \\sqrt{dt^{2} - d\\vec{x}^{2}} $$\nIn comparison, the classical action with an added potential term is:\n$$ S_{NR} = \\int{ dt \\left(\\frac{1}{2}m \\left( \\frac{d\\vec{x}}{dt} \\right)^{2} - V(x) \\right) } $$\nTo include interactions in relativistic spacetime, we consider adding the potential term either outside or inside the square root.\nOutside the square root $$ S = -\\int{ [-m \\sqrt{-\\eta_{\\mu \\nu} dx^{\\mu} dx^{\\nu} } + V(x)dt] } $$ By promoting the scalar potential to the vector potential and completing the symmetry, we get:\n$$ S = -\\int{ [-m \\sqrt{-\\eta_{\\mu \\nu} dx^{\\mu} dx^{\\nu} } + A_{\\mu}(x)dx^{\\mu}] } $$\nInside the square root $$ S = -\\int{ -m \\sqrt{\\left(1+\\frac{2V}{m}\\right)dt^{2} - d\\vec{x}^{2}} } $$ Here, symmetry and promotion to Lorentz invariance give us the curved spacetime version:\n$$ S = -m \\int{ \\sqrt{-g_{\\mu \\nu} dx^{\\mu} dx^{\\nu}} } $$\nMaxwell\u0026rsquo;s Equations in Hindsight Extremizing the action and requiring the variation to vanish gives:\n$$ \\delta S = \\delta \\left(-m\\int{d\\tau \\sqrt{-\\eta_{\\mu \\nu} \\frac{dx^{\\mu}}{d\\tau} \\frac{dx^{\\nu}}{d\\tau}} + \\int{d\\tau A_{\\mu}(x(\\tau)) \\frac{dx^{\\mu}}{d\\tau}}} \\right) $$\nFirst term $$ \\delta \\left( -m\\int{d\\tau \\sqrt{-\\eta_{\\mu \\nu} \\frac{dx^{\\mu}}{d\\tau} \\frac{dx^{\\nu}}{d\\tau}} } \\right) = m \\int{d\\tau \\eta_{\\mu \\nu} \\frac{dx^{\\mu}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau} = -m \\int{d\\tau \\eta_{\\mu \\rho} \\frac{d^{2}x^{\\mu}}{d\\tau ^{2}}dx^{\\rho}}}$$\nSecond term $$ \\delta \\int{d\\tau A_{\\mu}(x) \\frac{dx^{\\mu}}{d\\tau}} = \\int{d\\tau \\left[A_{\\mu}\\frac{d\\delta x^{\\mu}}{d\\tau} + \\delta_{\\nu}A_{\\mu}\\delta x^{\\nu} \\frac{dx^{\\mu}}{d\\tau}\\right]} $$\n$$ \\int{d\\tau A_{\\mu}(x)\\frac{d\\delta x^{\\mu}}{d\\tau}} = -\\int{d\\tau \\frac{dA_{\\mu}(x)}{d\\tau}\\delta x^{\\mu}} = -\\int{d\\tau \\delta_{\\nu} A_{\\mu}(x) \\frac{dx^{\\nu}}{d\\tau} \\delta x^{\\mu}}$$\n$$ \\delta \\int{d\\tau A_{\\mu}(x) \\frac{dx^{\\mu}}{d\\tau}} = \\int{d\\tau \\left( \\delta_{\\mu}A_{\\nu} - \\delta_{\\nu}A_{\\mu} \\right) \\frac{dx^{\\nu}}{d\\tau} \\delta x^{\\mu}} $$\nDefining the antisymmetric tensor field\n$$ F_{\\mu \\nu}(x) \\equiv \\delta_{\\mu}A_{\\nu}(x) - \\delta_{\\nu}A_{\\mu}(x) $$\nThus, the variation of the action becomes:\n$$ \\delta S = \\int{d\\tau \\left( -m \\eta_{\\mu \\rho} \\frac{d^{2}x^{\\mu}}{d\\tau^{2}} \\delta x^{\\rho} + F_{\\mu \\nu}\\frac{dx^{\\nu}}{d\\tau} \\delta x^{\\mu} \\right)} $$\nDefine\n$$ F_{\\nu}^{\\mu} \\equiv \\eta^{\\mu \\lambda} F_{\\lambda \\nu} \\Rightarrow F_{\\nu}^{\\mu} \\frac{dx^{\\nu}}{d\\tau} \\eta_{\\mu \\rho} \\delta x^{\\rho} $$\nThis results in the Lorentz force law in tensor form:\n$$ m\\frac{d^{2}x^{\\mu}}{d\\tau^{2}} = F_{\\nu}^{\\mu}(x) \\frac{dx^{\\nu}}{d\\tau} $$\nFields and Particle Interaction The action for multiple particles becomes:\n$$ S = -\\sum_{a} m_{a} \\int{d\\tau_{a} \\sqrt{-\\eta_{\\mu \\nu} \\frac{dx_{a}^{{\\mu}}}{d\\tau_{a}} \\frac{dx_{a}^{\\nu}}{d\\tau_{a}} }} + \\sum_{a} e_{a} \\int{d\\tau_{a}A_{\\mu}(x_{a}(\\tau_{a}))\\frac{dx_{a}^{\\mu}}{d\\tau_{a}}} $$\nThe field **\\(A_{\\mu}\\) covers the entire space, but each particle couples to it locally with strength \\( e_{a} \\) which we recognize as the particle\u0026rsquo;s charge.\nGauge Invariant Focusing on the second term \\( \\int{A_{\\mu}(x)dx^{\\mu}} \\)\nThis is invariant under the gauge transformation:\n$$ A_{\\mu}(x) \\rightarrow \\tilde{A_{\\mu}} = A_{\\mu}(x) + \\delta_{\\mu} \\Lambda (x) $$\nThe variation of this term vanishes:\n$$ \\int{\\delta_{\\mu} \\Lambda (x) dx^{\\mu}} = \\int_{\\tau_{i}}^{\\tau_f}d \\tau \\frac{dx^{\\mu}}{d\\tau}\\delta_{\\mu} \\Lambda(x) = \\int_{\\tau_{i}}^{\\tau_{f}} d\\tau \\frac{d}{d\\tau} \\Lambda (x)=0$$\nFrom this, we conclude that \\( A_{\\mu}(x) \\) contains non-physical degrees of freedom that can be removed by choosing an appropriate \\( \\Lambda (x) \\). Varying this gauge-invariant action leads to \\( F_{\\mu \\nu}\\) which is itself gauge-invariant.\nSquaring \\( F_{\\mu \\nu} \\) gives the Lorentz scalar: $$ \\int{d^{4}x \\left( -\\frac{1}{4}F^{\\mu \\nu} F_{\\mu \\nu} \\right)} $$\nThis is Maxwell\u0026rsquo;s Lagrangian:\n$$ \\mathcal{L} = -\\frac{1}{4}F^{\\mu \\nu} F_{\\mu \\nu} $$\nMaxwell\u0026rsquo;s Lagrangian Varying the Lagrangian results in Maxwell\u0026rsquo;s equations in free space:\n$$ \\delta_{\\mu} F^{\\mu \\nu} = 0 $$\nIn the presence of currents, we obtain:\n$$ \\delta_{\\mu} F^{\\mu \\nu}(x) = -J^{\\nu}(x)$$\nMaxwell\u0026rsquo;s Equation in Vector Forms For \\( \\nu = 0 \\), $$ \\delta_{i}F^{i0}=-\\delta_{i} E^{i} = - \\vec{\\triangledown} \\cdot \\vec{E} = \\rho $$\nFor \\( \\nu = 3 \\), $$ \\delta_{\\mu}F^{\\mu 3} = \\delta_{0}F^{03} + \\delta_{1}F^{13} + \\delta_{2}F^{23} = \\delta_{0}E^{3} - \\delta_{1}E^{2} + \\delta_{2}B^{1}$$\n$$ \\vec{\\triangledown} \\times \\vec{B} = \\frac{\\delta \\vec{B}}{\\delta t} + \\vec{J}$$\nA Fun Game to Play Exploring the relationship between spacetime and matter interaction offers exciting possibilities. Imagine if our spacetime structure changes:\n$$\\eta_{\\mu\\nu} \\rightarrow \\eta_{\\mu\\nu}^{\\prime}$$\nWhat new interactions or fields could emerge? It\u0026rsquo;s a compelling thought experiment, highlighting the beauty of the theory\u0026rsquo;s flexibility.\nBibliography Zee (2013) Zee,\u0026#32; A.\u0026#32; (2013). \u0026#32; Einstein gravity in a nutshell. \u0026#32; Princeton University Press.\u0026#32;Retrieved from\u0026#32; https://books.google.co.jp/books?id=5Dy1hlKvmCYC ","permalink":"https://htsod.github.io/posts/maxwell_eqns_derive/","summary":"\u003cp\u003eRelativity\u0026rsquo;s action principle constrains how light and matter interact within spacetime. By placing the potential term either inside or outside the action square root, we derive the familiar interactions of gravity or electromagnetism between matter. This post offers a top-down view of electromagnetism\u0026rsquo;s derivation from these fundamental principles.\u003c/p\u003e\n\u003ch2 id=\"relativistic-action\"\u003eRelativistic Action\u003c/h2\u003e\n\u003cp\u003eTo incorporate relativistic effects, the action is written as:\u003c/p\u003e\n\u003cp\u003e$$ S = -m \\int{ \\sqrt{-\\eta_{\\mu \\nu} dx^{\\mu} dx^{\\nu}} } = -m \\sqrt{dt^{2} - d\\vec{x}^{2}} $$\u003c/p\u003e","title":"Top-down derivation of Electromagnetism"},{"content":"Renormalization Group Approach in Dynamical System The renormalization group (RG) method is an approximation technique initially developed for solving strongly interacting many-body problems in quantum field theory, where perturbative solutions deviate from the actual solutions. The fundamental concept of the renormalization group approach is to eliminate irrelevant degrees of freedom in a physical system while preserving its essential characteristics ( Citation: P. Kopietz,\u0026#32;2010 P. Kopietz,\u0026#32; F.\u0026#32; (2010). \u0026#32; Introduction to the Functional Renormalization Group (1). \u0026#32; Springer, Berlin Heidelberg 2010. https://doi.org/10.1007/978-3-642-05094-7 ) . This method has been extended to the field of statistical mechanics, providing a quantitative description of universality and scale invariance phenomena.\nUniversality and Scale Invariance Universality refers to the observation that distinct physical systems can exhibit similar behavior near their critical points. Scale invariance occurs when the qualitative features of a system remain unchanged as we vary the system\u0026rsquo;s size ( Citation: Sethna,\u0026#32;2020 Sethna,\u0026#32; J.\u0026#32; (2020). \u0026#32; Entropy, Order Parameters, and Complexity (2). \u0026#32; Clarendon Press. ) . These concepts offer a framework for categorizing phenomena that exhibit self-replicating patterns in space (fractal structures) and time (period doubling). In this review, we will explore the relationship between changing the scale of a system and the emergence of chaos at certain parameter limits. By applying the renormalization group method, we can establish the close connection between these concepts and provide a unifying language for their analysis.\nRenormalization Procedure: Decimation and Rescaling The renormalization group method involves two key steps: decimation (mode reduction) and rescaling. Decimation eliminates irrelevant degrees of freedom in the system, while rescaling ensures that the remaining parameters are adjusted in such a way that the essential properties of the system are preserved.\nWe can describe the action of the renormalization group on a system using the operator \\(R(b;g)\\), where $g$ represents the relevant parameters or coupling terms that describe the system, and \\(b\\) defines the scaling operation. By applying this operator recursively, we can track the evolution of the parameters \\(g\\) as we scale the system by a factor of \\(b\\).\n$$ \\vec{g}^{\\prime} = \\vec{R}(b;\\vec{g}) $$ $$ \\vec{g}^{\\prime\\prime} = \\vec{R}(b^{\\prime};\\vec{g}^{\\prime}) = \\vec{R}(b^{\\prime};\\vec{R}(b;\\vec{g})) = \\vec{R}(b^{\\prime}b;\\vec{g}^{\\prime}) $$\nBy repeatedly applying this operation $n$ times, we obtain the relationship:\n$$ \\vec{g}^{(n)} = \\vec{R}(b;\\vec{g})^{n-1}=\\vec{R}(b^{(n)};\\vec{g}) $$\nThis equation signifies that by removing irrelevant degrees of freedom, we modify the system\u0026rsquo;s coupling parameters \\(\\vec{g}\\). To ensure that \\(\\vec{g}\\) remains fixed at each iteration, the scaling operation $b$ must be recursively applied.\nThe conceptual understanding of the renormalization group method is straightforward, but the challenge lies in determining the form of the operator \\(\\vec{R}(b;\\vec{g})\\), as we will see in the case of the logistic map.\nExample I: One-dimensional Ising Model In the case of one dimension Ising model, every resursive process scales the total number of lattice by \\( \\frac{1}{2} \\) while keeping the form of partition function fixed. As a result, the coupling constant \\( g \\equiv \\frac{J}{T} \\) is mapped to \\( g^{\\prime} \\) accordingly to match the partition function.\nBy scaling the lattice point by half, the transfer matrix is rescaled as such\n$$ T^{\\prime}=e^{f^{\\prime}}[[e^{g^{\\prime}+h^{\\prime}}, e^{-g^{\\prime}}], [e^{-g^{\\prime}}, E^{g^{\\prime} - h^{\\prime}}]] = e^{2f}[e^{2g+2h} + e^{-2g}] $$\nWhich gives us three equations to solve for the three new coupling constant in terms of the old coupling constant. Writting out explicitly.\nThe renormalized external magnetic field $$ h^{\\prime} = h + \\frac{1}{2}\\ln{\\left[ \\frac{\\cosh{(2g+h)}}{\\cosh{2g-h}} \\right]} $$ In the absent of external magnetic field\nThe renormalized free energy $$ f^{\\prime} = 2f + + \\ln{\\left( 2 \\sqrt{2\\cosh{2g}} \\right)} $$\nThe renormalized nearest-neighbor interaction $$ \\tanh{g^{\\prime}} = \\tanh^{2}g $$\nThe RG flow and fixed points Defining \\( x_{0} \\) to be\n$$ x_{0} = \\tanh{\\left( \\frac{J}{T} \\right)} = \\tanh{g} $$\nwhich follows that\n$$ \\tanh{g_{1}} = x_{1} = x_{0}^{2} $$\nAnd we obtain the recursion relation of the fraction \\( g \\)\n$$ x_{n+1} = x_{n}^{2} $$ $$ x_{n} = \\tanh{\\left( \\frac{J}{T_{n}} \\right)} $$\nSince hyperbolic tangent is asmptotic to -1 and +1, hence the recursion will map the hyperbolic tangent from \\( |1| \\) to \\( 0 \\), or zero temperature to infinite temperature as we shrinks the system.\nAlternatively, the RG flow could be captured by calculating the correlation function \\( G(r_{i} - r_{j}) \\) and the correlation length \\( \\xi \\). Recall that \\( \\xi \\) is defined in terms of the asymptotic behavor of the correlation function \\( G(r_{i} - r_{j}) \\) for \\( |r_{i} - r_{j}| \\rightarrow \\infty \\), or, equivalently, in terms of the behavior of its Fourier transfrom \\( G(k) \\) for small wave vectors.\n$$ \\xi^{\\prime} \\equiv \\xi (x^{\\prime}) = \\frac{\\xi (x)}{b} $$\n$$ \\xi (x^{2}) = \\frac{\\xi (x)}{2} $$\n$$ \\xi (x) = - \\frac{a_{0}}{\\ln{x}} $$\nHence\n$$ \\xi \\sim \\frac{a}{2} e^{2J/T} $$\nExample II: Logistic Map and Period Doubling The logistic map is an example of a discrete-time dynamical system defined by the recursion law:\n$$ x_{n+1} = f(x_{n})=\\mu x (1-x) $$\nAlthough the equation appears simple, it exhibits a captivating phenomenon known as period doubling as the bifurcation parameter $\\mu$ increases, ultimately leading to chaos at the limit $\\mu_{\\infty}$, as illustrated in Figure below.\nInterestingly, a constant $\\delta$ known as the Feigenbaum constant emerges and remains fixed across certain families of functions. It can be stated as in the limit of $n \\rightarrow \\infty$\n$$ \\delta = \\lim_{n\\rightarrow \\infty} \\frac{\\mu_{n}-\\mu_{n-1}}{\\mu_{n+1}-\\mu_{n}} $$\nThrough numerical analysis, the Feigenbaum constant has been calculated to be a value close to $4.66914$.\nThe RG method provides a quantitative approach to calculating the Feigenbaum constant and generalizing the behavior of period doubling phenomena to a function space. However, the mathematical derivations involved can be complex, and interested readers are encouraged to consult relevant papers ( Citation: Sfondrini,\u0026#32;2012 Sfondrini,\u0026#32; A. \u0026#32; (2012). \u0026#32;Introduction to universality and renormalization group techniques.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/1210.2262 ) for more detailed information.\nTo keep it simple, we will only be focusing on providing a descriptive account of the steps involved in calculating the Feigenbaum constant, with the emphasis on the interpretation of the results and their significance in the dynamical analysis of chaos.\nTo summarize the steps, we first make observations about the logistic map, recognizing it as a unimodal function. We also note that other unimodal functions exhibit period doubling behavior. We define a functional subspace of unimodal functions and seek to apply the RG method in a way that preserves this characteristic of being unimodel. Once we have the form of \\(R(b;g)\\) at hand, we evaluate the behavior of the fixed point \\(R(\\phi^{ast})=\\phi^{ast}\\) where $\\phi$ denotes the flow. Intuitively, we expect to find one unstable manifold with eigenvalues of modulus greater than one that correspond to bifurcation variable \\(\\mu_{\\infty}\\) that destabilizes the orbit. And an infinite stable manifold with eigenvalues of modulus less than one corresponds to \\(mu_{n}\\) that corresponds to stable oribit with period \\(2^{n}\\). By visualizing the mathematical spaces (refer to the figure below), we can observe that they share similar features with period doubling, albeit in different domains. The spacing of the stable and unstable manifolds follows a geometric series, defining the Feigenbaum constant. By making suitable ansatz for the sequence and fitting it with \\(R(\\phi)\\), we are able to calculate \\(\\sigma=4.66914\\).\nThis derivation clarifies some confusions and provides a unique perspective on the period doubling phenomenon. It demonstrates how the logistic map, initially perceived as a one-dimensional system that cannot exhibit chaotic behavior, actually resides in an infinite-dimensional space that converges to chaos. Moreover, it reveals that unimodal mapping is the underlying universality group characterized by the Feigenbaum constant, with the logistic map representing just one special case. In simpler derivations, numerical mappings of one set of \\(\\phi_{n}$ to $\\phi_{n-1}\\)inform us of the functional form of the renormalization group operator \\(R(\\phi)=-ag(g(-z/a))\\). Without making further assumptions, this form also enables the calculation of the Feigenbaum constant. In this sense, the renormalization group operator captures the essential structure of the onset of chaos behavior.\nExample III: Small-World Network Model Ongoing\nBibliography Sfondrini (2012) Sfondrini,\u0026#32; A. \u0026#32; (2012). \u0026#32;Introduction to universality and renormalization group techniques.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/1210.2262 Sethna (2020) Sethna,\u0026#32; J.\u0026#32; (2020). \u0026#32; Entropy, Order Parameters, and Complexity (2). \u0026#32; Clarendon Press. P. Kopietz (2010) P. Kopietz,\u0026#32; F.\u0026#32; (2010). \u0026#32; Introduction to the Functional Renormalization Group (1). \u0026#32; Springer, Berlin Heidelberg 2010. https://doi.org/10.1007/978-3-642-05094-7 ","permalink":"https://htsod.github.io/posts/rg_method/","summary":"\u003ch2 id=\"renormalization-group-approach-in-dynamical-system\"\u003eRenormalization Group Approach in Dynamical System\u003c/h2\u003e\n\u003cp\u003eThe renormalization group (RG) method is an approximation technique initially developed for solving strongly interacting many-body problems in quantum field theory, where perturbative solutions deviate from the actual solutions. The fundamental concept of the renormalization group approach is to eliminate irrelevant degrees of freedom in a physical system while preserving its essential characteristics \n\n\n\n\n\u003cspan class=\"hugo-cite-intext\"\n        itemprop=\"citation\"\u003e(\u003cspan class=\"hugo-cite-group\"\u003e\n\n          \u003ca href=\"#plf2010\"\u003e\u003cspan class=\"visually-hidden\"\u003eCitation: \u003c/span\u003e\u003cspan itemprop=\"author\" itemscope itemtype=\"https://schema.org/Person\"\u003e\u003cmeta itemprop=\"givenName\" content=\"F. Schutz\"\u003e\u003cspan itemprop=\"familyName\"\u003eP. Kopietz\u003c/span\u003e\u003c/span\u003e,\u0026#32;\u003cspan itemprop=\"datePublished\"\u003e2010\u003c/span\u003e\u003c/a\u003e\u003cspan class=\"hugo-cite-citation\"\u003e \n\n\n\n\n\n\n\n\n\n\n\u003cspan itemscope \n      itemtype=\"https://schema.org/Book\"\n      data-type=\"book\"\u003e\u003cspan itemprop=\"author\" itemscope itemtype=\"https://schema.org/Person\"\u003e\u003cspan itemprop=\"familyName\"\u003eP. Kopietz\u003c/span\u003e,\u0026#32;\n    \u003cmeta itemprop=\"givenName\" content=\"F. Schutz\" /\u003e\n    F.\u003c/span\u003e\u0026#32;\n    (\u003cspan itemprop=\"datePublished\"\u003e2010\u003c/span\u003e).\n  \u0026#32;\u003cspan itemprop=\"name\"\u003e\n    \u003ci\u003e\u003c!-- raw HTML omitted --\u003eIntroduction to the Functional Renormalization Group\u003c!-- raw HTML omitted --\u003e\u003c/i\u003e\u003c/span\u003e (\u003cspan\u003e1\u003c/span\u003e).\n  \u0026#32;\n  \u003cspan itemprop=\"publisher\"\n             itemtype=\"http://schema.org/Organization\"\n             itemscope=\"\"\u003e\n    \u003cspan itemprop=\"name\"\u003eSpringer, Berlin Heidelberg 2010\u003c/span\u003e\u003c/span\u003e.\n  \u003ca href=\"https://doi.org/10.1007/978-3-642-05094-7\"\n     itemprop=\"identifier\"\n     itemtype=\"https://schema.org/URL\"\u003ehttps://doi.org/10.1007/978-3-642-05094-7\u003c/a\u003e\u003c/span\u003e\n\n\n\n\n\u003c/span\u003e\u003c/span\u003e)\u003c/span\u003e\n. This method has been extended to the field of statistical mechanics, providing a quantitative description of universality and scale invariance phenomena.\u003c/p\u003e","title":"Renormalization Group method with Examples"}]